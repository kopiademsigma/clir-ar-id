{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['الحمد', 'لله', 'الذي', 'هدانا', 'لهذا', 'وما', 'كنا', 'لنهتدي', 'لولا', 'ان', 'هدانا', 'الله']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from camel_tools.tokenizers.word import simple_word_tokenize\n",
    "\n",
    "# def clean_corpus_line(line):\n",
    "#     # Skip metadata and markup\n",
    "#     if line.startswith(\"#META#\") or line.startswith(\"# Page\") or line.startswith(\"<\"):\n",
    "#         return \"\"\n",
    "#     # Remove tildes and HTML tags\n",
    "#     line = re.sub(r'[~<>/\"]', ' ', line)\n",
    "#     return line.strip()\n",
    "def clean_line(line):\n",
    "    # Remove leading/trailing spaces\n",
    "    line = line.strip()\n",
    "\n",
    "    # Skip metadata and page markers\n",
    "    if line.startswith(\"#META#\") or line.startswith(\"# Page\") or line.startswith(\"######\"):\n",
    "        return \"\"\n",
    "\n",
    "    # Remove lines that are just hashes, dots, or markup\n",
    "    if re.match(r'^#+$', line):  # only hashes\n",
    "        return \"\"\n",
    "    if re.match(r'^[\\.\\s]+$', line):  # only dots/spaces\n",
    "        return \"\"\n",
    "    if line.startswith(\"<\") and line.endswith(\">\"):  # pure html tags\n",
    "        return \"\"\n",
    "\n",
    "    # Remove <span> tags and similar\n",
    "    line = re.sub(r'<.*?>', ' ', line)\n",
    "\n",
    "    # Remove \"~~\" continuation markers\n",
    "    line = line.replace(\"~~\", \" \")\n",
    "\n",
    "    # Remove stray #\n",
    "    line = line.replace(\"#\", \" \")\n",
    "\n",
    "    return line.strip()\n",
    "\n",
    "\n",
    "def normalize_arabic(text):\n",
    "    text = re.sub(r'[\\u0617-\\u061A\\u064B-\\u0652]', '', text)  # tashkeel\n",
    "    text = re.sub(r'ـ', '', text)  # tatweel\n",
    "    text = re.sub(r'[إأآا]', 'ا', text)  # alif\n",
    "    text = re.sub(r'ى', 'ي', text)  # ya\n",
    "    text = re.sub(r'ة', 'ه', text)  # taa marbuta\n",
    "    return text\n",
    "\n",
    "def tokenize_arabic(text):\n",
    "    text = normalize_arabic(text)\n",
    "    tokens = simple_word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "# Example usage``\n",
    "raw_line = \"الحمد لله الذي هدانا لهذا وما كنا لنهتدي لولا أن هدانا الله\"\n",
    "tokens = tokenize_arabic(raw_line)\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cleaned:\n\u001b[1;32m      7\u001b[0m     normalized \u001b[38;5;241m=\u001b[39m normalize_arabic(cleaned)\n\u001b[0;32m----> 8\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m \u001b[43msimple_word_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormalized\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokens:\n\u001b[1;32m     10\u001b[0m         corpus\u001b[38;5;241m.\u001b[39mappend(tokens)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/camel_tools/tokenizers/word.py:82\u001b[0m, in \u001b[0;36msimple_word_tokenize\u001b[0;34m(sentence, split_digits)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _TOKENIZE_NUMBER_RE\u001b[38;5;241m.\u001b[39mfindall(sentence)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_TOKENIZE_RE\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindall\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "file_path = \"../fath_muin/0987ZaynDinMalibari.FathMucin.Shamela0011327-ara1.txt\"\n",
    "corpus = []\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        cleaned = clean_line(line)\n",
    "        if cleaned:\n",
    "            normalized = normalize_arabic(cleaned)\n",
    "            tokens = simple_word_tokenize(normalized)\n",
    "            if tokens:\n",
    "                corpus.append(tokens)\n",
    "\n",
    "print(\"First 5 tokenized lines:\")\n",
    "for line in corpus[:5]:\n",
    "    print(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
